{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ner\")\\\n",
    "    .master(\"local[1]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8G\")\\\n",
    "    .config(\"spark.driver.maxResultS1ize\", \"2G\") \\\n",
    "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:2.0.0\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"500m\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download CoNLL2003 dataset\n",
    "2. Save 3 files eng.train, eng.testa, eng.testa, into working dir ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example how to download CoNLL 2003 Dataset\n",
    "def download_conll2003_file(file):    \n",
    "    if not Path(file).is_file():\n",
    "        url = \"https://raw.githubusercontent.com/patverga/torch-ner-nlp-from-scratch/master/data/conll2003/\" + file\n",
    "        urllib.request.urlretrieve(url, file)\n",
    "        \n",
    "download_conll2003_file(\"eng.train\")\n",
    "download_conll2003_file(\"eng.testa\")\n",
    "download_conll2003_file(\"eng.testb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Download Glove word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"glove.6B.zip\"\n",
    "if not Path(\"glove.6B.zip\").is_file():\n",
    "    url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
    "    print(\"Start downoading Glove Word Embeddings. It will take some time, please wait...\")\n",
    "    urllib.request.urlretrieve(url, \"glove.6B.zip\")\n",
    "    print(\"Downloading finished\")\n",
    "    \n",
    "if not Path(\"glove.6B.100d.txt\").is_file():\n",
    "    zip_ref = zipfile.ZipFile(file, 'r')\n",
    "    zip_ref.extractall(\"./\")\n",
    "    zip_ref.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_pipeline():\n",
    "    glove = WordEmbeddingsLookup()\\\n",
    "      .setInputCols([\"sentence\", \"token\"])\\\n",
    "      .setOutputCol(\"glove\")\\\n",
    "      .setEmbeddingsSource(\"glove.6B.100d.txt\", 100, 2)\n",
    "\n",
    "    nerTagger = NerCrfApproach()\\\n",
    "      .setInputCols([\"sentence\", \"token\", \"pos\", \"glove\"])\\\n",
    "      .setLabelColumn(\"label\")\\\n",
    "      .setOutputCol(\"ner\")\\\n",
    "      .setMinEpochs(1)\\\n",
    "      .setMaxEpochs(10)\\\n",
    "      .setLossEps(1e-3)\\\n",
    "      .setExternalFeatures(\"../../../src/test/resources/ner-corpus/dict.txt\", \",\")\\\n",
    "      .setL2(1)\\\n",
    "      .setC0(1250000)\\\n",
    "      .setRandomSeed(100)\\\n",
    "      .setVerbose(2)\n",
    "      \n",
    "    pipeline = Pipeline(\n",
    "        stages = [\n",
    "        glove,\n",
    "        nerTagger\n",
    "      ])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def readDataset(file):\n",
    "    from sparknlp.dataset import CoNLL\n",
    "    conll = CoNLL()\n",
    "    return conll.readDataset('eng.train')\n",
    "    \n",
    "def train_model(file):\n",
    "    global spark\n",
    "    \n",
    "    print(\"Dataset Reading\")\n",
    "    \n",
    "    start = time.time()\n",
    "    dataset = readDataset(file)\n",
    "    print(\"Done, {}\\n\".format(time.time() - start))\n",
    "\n",
    "    print(\"Start fitting\")\n",
    "    pipeline = get_pipeline()\n",
    "\n",
    "    return pipeline.fit(dataset)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-e638fc6d6114>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-e638fc6d6114>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    annotation_schema = StructType([,\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, udf, explode\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "annotation_schema = StructType([\n",
    "    StructField(\"annotatorType\", StringType()),\n",
    "    StructField(\"begin\", IntegerType(), False),\n",
    "    StructField(\"end\", IntegerType(), False),\n",
    "    StructField(\"result\", StringType()),\n",
    "    StructField(\"metadata\", MapType(StringType(), StringType())),\n",
    "    StructField(\"calculations\", MapType(StringType(), ArrayType(FloatType()))),\n",
    "])\n",
    "\n",
    "\n",
    "def get_dataset_for_analysis(file, model):\n",
    "    global spark\n",
    "    \n",
    "    print(\"Dataset Reading\")\n",
    "    \n",
    "    start = time.time()\n",
    "    dataset = readDataset(file)\n",
    "    print(\"Done, {}\\n\".format(time.time() - start))\n",
    "    \n",
    "    predicted = model.transform(dataset)\n",
    "    \n",
    "    global annotation_schema\n",
    "    \n",
    "    zip_annotations = udf(\n",
    "      lambda x, y: list(zip(x, y)),\n",
    "      ArrayType(StructType([\n",
    "          StructField(\"predicted\", annotation_schema),\n",
    "          StructField(\"label\", annotation_schema)\n",
    "      ]))\n",
    "    )\n",
    "    \n",
    "    return predicted\\\n",
    "        .withColumn(\"result\", zip_annotations(\"ner\", \"label\"))\\\n",
    "        .select(explode(\"result\").alias(\"result\"))\\\n",
    "        .select(\n",
    "            col(\"result.predicted\").alias(\"predicted\"), \n",
    "            col(\"result.label\").alias(\"label\")\n",
    "        )\n",
    "        \n",
    "def printStat(label, correct, predicted, predictedCorrect):\n",
    "    prec = predictedCorrect / predicted if predicted > 0 else 0\n",
    "    rec = predictedCorrect / correct if correct > 0 else 0\n",
    "    f1 = (2*prec*rec)/(prec + rec) if prec + rec > 0 else 0\n",
    "    \n",
    "    print(\"{}\\t{}\\t{}\\t{}\".format(label, prec, rec, f1))\n",
    "        \n",
    "\n",
    "def test_dataset(file, model, ignore_tokenize_misses=True):\n",
    "    global spark\n",
    "    \n",
    "    started = time.time()\n",
    "\n",
    "    df = readDataset(file)\n",
    "    transformed = model.transform(df).select(\"label\", \"ner\")\n",
    "\n",
    "    labels = []\n",
    "    predictedLabels = []\n",
    "\n",
    "    for line in transformed.collect():\n",
    "        label = line[0]\n",
    "        ner = line[1]\n",
    "    \n",
    "        ner = {(a[\"begin\"], a[\"end\"]):a[\"result\"] for a in ner}\n",
    "\n",
    "        for a in label:\n",
    "            key = (a[\"begin\"], a[\"end\"])\n",
    "\n",
    "            label = a[\"result\"].strip()\n",
    "            predictedLabel = ner.get(key, \"O\").strip()\n",
    "            \n",
    "            if key not in ner and ignore_tokenize_misses:\n",
    "                continue\n",
    "                \n",
    "            labels.append(label)\n",
    "            predictedLabels.append(predictedLabel)\n",
    "        \n",
    "\n",
    "    correct = {}\n",
    "    predicted = {}\n",
    "    predictedCorrect = {}\n",
    "\n",
    "\n",
    "    print(len(labels))\n",
    "\n",
    "    for (lPredicted, lCorrect) in zip(predictedLabels, labels):\n",
    "        correct[lCorrect] = correct.get(lCorrect, 0) + 1\n",
    "        predicted[lPredicted] = predicted.get(lPredicted, 0) + 1\n",
    "\n",
    "        if lCorrect == lPredicted:\n",
    "            predictedCorrect[lPredicted] = predictedCorrect.get(lPredicted, 0) + 1\n",
    "\n",
    "    correct = { key: correct[key] for key in correct.keys() if key != 'O'}\n",
    "    predicted = { key: predicted[key] for key in predicted.keys() if key != 'O'}\n",
    "    predictedCorrect = { key: predictedCorrect[key] for key in predictedCorrect.keys() if key != 'O'}\n",
    "\n",
    "    tags = set(list(correct.keys()) + list(predicted.keys()))\n",
    "\n",
    "    print(\"label\\tprec\\trec\\tf1\")\n",
    "    totalCorrect = sum(correct.values())\n",
    "    totalPredicted = sum(predicted.values())\n",
    "    totalPredictedCorrect = sum(predictedCorrect.values())\n",
    "\n",
    "    printStat(\"Total\", totalCorrect, totalPredicted, totalPredictedCorrect)\n",
    "\n",
    "    for label in tags:\n",
    "        printStat(label, correct.get(label, 0), predicted.get(label, 0), predictedCorrect.get(label, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "folder = '.'\n",
    "train_file = os.path.join(folder, \"eng.train\")\n",
    "test_file_a = os.path.join(folder, \"eng.testa\")\n",
    "test_file_b = os.path.join(folder, \"eng.testb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Reading\n",
      "Done, 4.746060132980347\n",
      "\n",
      "Start fitting\n"
     ]
    }
   ],
   "source": [
    "model = train_model(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quality on training data\n",
      "203621\n",
      "label\tprec\trec\tf1\n",
      "Total\t0.9698192717452592\t0.9599624004934936\t0.9648656628284618\n",
      "I-LOC\t0.9827103372701814\t0.9740526188752112\t0.9783623249893934\n",
      "B-ORG\t1.0\t1.0\t1.0\n",
      "I-ORG\t0.989902315881901\t0.9018098190180982\t0.9438049393051486\n",
      "B-LOC\t1.0\t0.7272727272727273\t0.8421052631578948\n",
      "I-PER\t0.9843444227005871\t0.9944284687275341\t0.9893607510058112\n",
      "I-MISC\t0.880746561886051\t0.9839771729587358\t0.9295044578063446\n",
      "B-MISC\t1.0\t0.24324324324324326\t0.391304347826087\n",
      "\n",
      "\n",
      "Quality on validation data\n",
      "203621\n",
      "label\tprec\trec\tf1\n",
      "Total\t0.9698192717452592\t0.9599624004934936\t0.9648656628284618\n",
      "I-LOC\t0.9827103372701814\t0.9740526188752112\t0.9783623249893934\n",
      "B-ORG\t1.0\t1.0\t1.0\n",
      "I-ORG\t0.989902315881901\t0.9018098190180982\t0.9438049393051486\n",
      "B-LOC\t1.0\t0.7272727272727273\t0.8421052631578948\n",
      "I-PER\t0.9843444227005871\t0.9944284687275341\t0.9893607510058112\n",
      "I-MISC\t0.880746561886051\t0.9839771729587358\t0.9295044578063446\n",
      "B-MISC\t1.0\t0.24324324324324326\t0.391304347826087\n",
      "\n",
      "\n",
      "Quality on test data\n",
      "203621\n",
      "label\tprec\trec\tf1\n",
      "Total\t0.9698192717452592\t0.9599624004934936\t0.9648656628284618\n",
      "I-LOC\t0.9827103372701814\t0.9740526188752112\t0.9783623249893934\n",
      "B-ORG\t1.0\t1.0\t1.0\n",
      "I-ORG\t0.989902315881901\t0.9018098190180982\t0.9438049393051486\n",
      "B-LOC\t1.0\t0.7272727272727273\t0.8421052631578948\n",
      "I-PER\t0.9843444227005871\t0.9944284687275341\t0.9893607510058112\n",
      "I-MISC\t0.880746561886051\t0.9839771729587358\t0.9295044578063446\n",
      "B-MISC\t1.0\t0.24324324324324326\t0.391304347826087\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuality on training data\")\n",
    "test_dataset(train_file, model)\n",
    "\n",
    "print(\"\\n\\nQuality on validation data\")\n",
    "test_dataset(test_file_a, model)\n",
    "\n",
    "print(\"\\n\\nQuality on test data\")\n",
    "test_dataset(test_file_b, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Reading\n",
      "Done, 1.554076910018921\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'annotation_schema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-1ea3ec1a32ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_for_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9e1758abb878>\u001b[0m in \u001b[0;36mget_dataset_for_analysis\u001b[0;34m(file, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       ArrayType(StructType([\n\u001b[0;32m---> 21\u001b[0;31m           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predicted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m           \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       ]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'annotation_schema' is not defined"
     ]
    }
   ],
   "source": [
    "df = get_dataset_for_analysis(test_file_a, model)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pipeline().write().overwrite().save(\"./crf_pipeline\")\n",
    "model.write().overwrite().save(\"./crf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel, Pipeline\n",
    "\n",
    "Pipeline.read().load(\"./crf_pipeline\")\n",
    "sameModel = PipelineModel.read().load(\"./crf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nQuality on training data\")\n",
    "test_dataset(train_file, sameModel)\n",
    "\n",
    "print(\"\\n\\nQuality on validation data\")\n",
    "test_dataset(test_file_a, sameModel)\n",
    "\n",
    "print(\"\\n\\nQuality on test data\")\n",
    "test_dataset(test_file_b, sameModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
