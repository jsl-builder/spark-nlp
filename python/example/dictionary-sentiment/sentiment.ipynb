{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nlp.johnsnowlabs.com/assets/images/logo.png\" width=\"180\" height=\"50\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Sentiment Analysis\n",
    "\n",
    "In the following example, we walk-through a simple use case for our straight forward SentimentDetector annotator.\n",
    "\n",
    "This annotator will work on top of a list of labeled sentences which can have any of the following features\n",
    "    \n",
    "    positive\n",
    "    negative\n",
    "    revert\n",
    "    increment\n",
    "    decrement\n",
    "\n",
    "Each of these sentences will be used for giving a score to text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "#Setting location of resource Directory\n",
    "resource_path= \"../../../src/test/resources/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SentimentDetector\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\")\\\n",
    "    .config(\"spark.jar\", \"lib/sparknlp.jar\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"500m\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------------------+\n",
      "|itemid|sentiment|                text|\n",
      "+------+---------+--------------------+\n",
      "|     1|        0|                 ...|\n",
      "|     2|        0|                 ...|\n",
      "|     3|        1|              omg...|\n",
      "|     4|        0|          .. Omga...|\n",
      "|     5|        0|         i think ...|\n",
      "|     6|        0|         or i jus...|\n",
      "|     7|        1|       Juuuuuuuuu...|\n",
      "|     8|        0|       Sunny Agai...|\n",
      "|     9|        1|      handed in m...|\n",
      "|    10|        1|      hmmmm.... i...|\n",
      "|    11|        0|      I must thin...|\n",
      "|    12|        1|      thanks to a...|\n",
      "|    13|        0|      this weeken...|\n",
      "|    14|        0|     jb isnt show...|\n",
      "|    15|        0|     ok thats it ...|\n",
      "|    16|        0|    &lt;-------- ...|\n",
      "|    17|        0|    awhhe man.......|\n",
      "|    18|        1|    Feeling stran...|\n",
      "|    19|        0|    HUGE roll of ...|\n",
      "|    20|        0|    I just cut my...|\n",
      "+------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark. \\\n",
    "        read. \\\n",
    "        parquet(resource_path+\"sentiment.parquet\"). \\\n",
    "        limit(10000).cache()\n",
    "\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create appropriate annotators. We are using Sentence Detection, Tokenizing the sentences, and find the lemmas of those tokens. The Finisher will only output the Sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\")\n",
    "\n",
    "sentence_detector = SentenceDetector() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "lemmatizer = Lemmatizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"lemma\") \\\n",
    "    .setDictionary(resource_path+\"lemma-corpus-small/lemmas_small.txt\", key_delimiter=\"->\", value_delimiter=\"\\t\")\n",
    "        \n",
    "sentiment_detector = SentimentDetector() \\\n",
    "    .setInputCols([\"lemma\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment_score\") \\\n",
    "    .setDictionary(resource_path+\"sentiment-corpus/default-sentiment-dict.txt\", \",\")\n",
    "    \n",
    "finisher = Finisher() \\\n",
    "    .setInputCols([\"sentiment_score\"]) \\\n",
    "    .setOutputCols([\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train the pipeline, which is only being trained from external resources, not from the dataset we pass on. The prediction runs on the target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[document_assembler, sentence_detector, tokenizer, lemmatizer, sentiment_detector, finisher])\n",
    "model = pipeline.fit(data)\n",
    "result = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. filter the finisher output, to find the negative sentiment lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|itemid|sentiment|text                                                                                                                                     |\n",
      "+------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|102   |negative |  not a cool night.                                                                                                                      |\n",
      "|135   |negative | #squarespace brighten my bad day! i never win anything...                                                                               |\n",
      "|145   |negative | &quot;I want you so bad it's driving me  mad&quot;                                                                                      |\n",
      "|190   |negative | @copicmarker&quot; facebook.com/copic.marker if you're cool. Or if you're not cool. Maybe I'll send some cool .. http://tr.im/oyT7      |\n",
      "|362   |negative |   bad day.                                                                                                                              |\n",
      "|363   |negative |   bad day.....damn you @311. What kind of ticket sale was that.....                                                                     |\n",
      "|456   |negative | - My name is Amy. Iï¿½m only three My eyes are swollen I cannot see, I must be stupid, I must be bad What... http://tumblr.com/xfj1uain0|\n",
      "|503   |negative |  Another expensive weekend trip to the vet.                                                                                             |\n",
      "|526   |negative |  jus got some bad news                                                                                                                  |\n",
      "|588   |negative | at Chris Brown . . . I honestly dont feel bad for Rihanna ; anyways . . . Out nd such . . .                                             |\n",
      "+------+---------+-----------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.filter(\"sentiment != 'positive'\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
