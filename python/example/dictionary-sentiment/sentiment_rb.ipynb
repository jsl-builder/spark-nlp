{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://nlp.johnsnowlabs.com/assets/images/logo.png\" width=\"180\" height=\"50\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Pipeline\n",
    "\n",
    "This pipeline will be used to explain a number of important features of the Spark-NLP library; Sentence Detection, Tokenization, Spell Checking, and Sentiment Detection.\n",
    "The idea is to start with natural language as could have been entered by a user, and get sentiment associated to it. Let's walk through each of the stages!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark `2.4` and Spark NLP `???`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Call necessary imports and set the resource path to read local data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import array_contains\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "\n",
    "# location of pre-trained pipelines\n",
    "resource_path= \"../demo_pipelines/movies_sentiment\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load SparkSession if not already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Sentiment_Rule_Based\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2G\")\\\n",
    "    .config(\"spark.jars.packages\", \"JohnSnowLabs:spark-nlp:1.8.3\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"500m\")\\\n",
    "    .config(\"spark.jars\", \"/tmp/sparknlp.jar\")\\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/tmp/sparknlp.jar\")\\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/tmp/sparknlp.jar\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Load our predefined pipeline containing all the important annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = PipelineModel.load(\"../demo_pipelines/movies_sentiment_analysis_en_1.8.0_2.4_1552694056982\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Create some user opinions for some movies, keep an eye on the spelling, we'll get back to that soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDocs = [\n",
    "    \"I felt so disapointed to see this very uninspired film. I recommend others to awoid this movie is not good.\",\n",
    "    \"This was movie was amesome, everything was nice.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['I felt so disapointed to see this very uninspired film.',\n",
       "   'I recommend others to awoid this movie is not good.'],\n",
       "  ['negative']),\n",
       " (['This was movie was amesome, everything was nice.'], ['positive'])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.base import LightPipeline\n",
    "lp = LightPipeline(pipeline)\n",
    "result = lp.annotate(testDocs)\n",
    "[(r['sentence'], r['my_sda_scores']) for r in result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### [Optional] - inspect intermmediate stages - spell checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dfeea3199851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checked_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-dfeea3199851>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checked_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'zip'"
     ]
    }
   ],
   "source": [
    "[list(zip(r['token'],r['checked_token'])) for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'checked_token': ['I',\n",
       "   'felt',\n",
       "   'so',\n",
       "   'disappointed',\n",
       "   'to',\n",
       "   'see',\n",
       "   'this',\n",
       "   'very',\n",
       "   'uninspired',\n",
       "   'film',\n",
       "   '.',\n",
       "   'I',\n",
       "   'recommend',\n",
       "   'others',\n",
       "   'to',\n",
       "   'avoid',\n",
       "   'this',\n",
       "   'movie',\n",
       "   'is',\n",
       "   'not',\n",
       "   'good',\n",
       "   '.'],\n",
       "  'document': ['I felt so disapointed to see this very uninspired film. I recommend others to awoid this movie is not good.'],\n",
       "  'my_sda_scores': ['negative'],\n",
       "  'sentence': ['I felt so disapointed to see this very uninspired film.',\n",
       "   'I recommend others to awoid this movie is not good.'],\n",
       "  'token': ['I',\n",
       "   'felt',\n",
       "   'so',\n",
       "   'disapointed',\n",
       "   'to',\n",
       "   'see',\n",
       "   'this',\n",
       "   'very',\n",
       "   'uninspired',\n",
       "   'film',\n",
       "   '.',\n",
       "   'I',\n",
       "   'recommend',\n",
       "   'others',\n",
       "   'to',\n",
       "   'awoid',\n",
       "   'this',\n",
       "   'movie',\n",
       "   'is',\n",
       "   'not',\n",
       "   'good',\n",
       "   '.']},\n",
       " {'checked_token': ['This',\n",
       "   'was',\n",
       "   'movie',\n",
       "   'was',\n",
       "   'awesome',\n",
       "   ',',\n",
       "   'everything',\n",
       "   'was',\n",
       "   'nice',\n",
       "   '.'],\n",
       "  'document': ['This was movie was amesome, everything was nice.'],\n",
       "  'my_sda_scores': ['positive'],\n",
       "  'sentence': ['This was movie was amesome, everything was nice.'],\n",
       "  'token': ['This',\n",
       "   'was',\n",
       "   'movie',\n",
       "   'was',\n",
       "   'amesome',\n",
       "   ',',\n",
       "   'everything',\n",
       "   'was',\n",
       "   'nice',\n",
       "   '.']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
