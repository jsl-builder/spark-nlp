{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "sys.path.append('../')\n",
    "from ner.embeddings_resolver import BertEmbeddingsResolver\n",
    "from ner.ner_model_saver import NerModelSaver\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Manully add sparknlp developer library\n",
    "sparknlp_path = '../../'\n",
    "if sparknlp_path:\n",
    "    sys.path.append(sparknlp_path)\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.embeddings import *\n",
    "import sparknlp \n",
    "\n",
    "import time\n",
    "import zipfile\n",
    "#Setting location of resource Directory\n",
    "resource_path= \"../../../src/test/resources/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(url, folder):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    zip_file = folder + \".zip\"\n",
    "    if not Path(zip_file).is_file():\n",
    "        print(\"Downloading \" + url)\n",
    "        urllib.request.urlretrieve(url, zip_file)\n",
    "    if not os.path.exists(folder):\n",
    "        print(\"Unziping \")\n",
    "        zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
    "        zip_ref.extractall(\"./\")\n",
    "        zip_ref.close()\n",
    "\n",
    "\n",
    "def get_service_token_ids(source_bert_folder):\n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "    with open(os.path.join(source_bert_folder, \"vocab.txt\")) as f:\n",
    "        for line, row in enumerate(f):\n",
    "            row = row.strip()\n",
    "            if row == '[CLS]':\n",
    "                start_id = line\n",
    "            if row == '[SEP]':\n",
    "                end_id = line\n",
    "    return (start_id, end_id)\n",
    "\n",
    "\n",
    "def create_model(source_bert_folder, export_dir, max_length = 256, batch_size = 5):\n",
    "    tf.reset_default_graph()\n",
    "    is_cased = 'uncased' not in source_bert_folder.lower()\n",
    "    print(\"source_bert_folder: {}\".format(source_bert_folder))\n",
    "    print(\"is_cased: {}\".format(is_cased))\n",
    "    resolver = BertEmbeddingsResolver(source_bert_folder, max_length, lowercase=is_cased)\n",
    "    saver = NerModelSaver(resolver, None)\n",
    "    saver.save_models(export_dir)\n",
    "    resolver.session.close()\n",
    "    shutil.copyfile(os.path.join(source_bert_folder, 'vocab.txt'),\n",
    "                    os.path.join(export_dir, 'vocab.txt'))\n",
    "    dim = resolver.config.hidden_size\n",
    "    model = BertEmbeddings.loadFromPython(export_dir, spark) \\\n",
    "        .setMaxSentenceLength(max_length) \\\n",
    "        .setBatchSize(batch_size) \\\n",
    "        .setDimension(dim) \\\n",
    "        .setCaseSensitive(is_cased) \\\n",
    "        .setInputCols([\"sentence\", \"wordpiece\"]) \\\n",
    "        .setOutputCol(\"bert\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def download_and_convert(url, name, max_length = 256, batch_size = 5, dst_folder = 'models'):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    download_model(url, name)\n",
    "    model = create_model(name, name + 'export_dir', 256, 5)\n",
    "    # Remove but it's possible to use this model\n",
    "    shutil.rmtree(name + 'export_dir')\n",
    "    shutil.rmtree(name)\n",
    "    model.write().overwrite().save(os.path.join(dst_folder, name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find models and source code here https://github.com/google-research/bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Base uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "name = 'uncased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Large uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip'\n",
    "name = 'uncased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Base cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip'\n",
    "name = 'cased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Large cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip'\n",
    "name = 'cased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upload all generated models from folder \"models\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
