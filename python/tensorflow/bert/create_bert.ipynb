{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "sys.path.append('../')\n",
    "from ner.embeddings_resolver import BertEmbeddingsResolver\n",
    "from ner.ner_model_saver import NerModelSaver\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Manully add sparknlp developer library\n",
    "sparknlp_path = '../../'\n",
    "if sparknlp_path:\n",
    "    sys.path.append(sparknlp_path)\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.embeddings import *\n",
    "import sparknlp \n",
    "\n",
    "import time\n",
    "import zipfile\n",
    "#Setting location of resource Directory\n",
    "resource_path= \"../../../src/test/resources/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version\n",
      "2.2.0-rc2\n",
      "Apache Spark version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version\")\n",
    "sparknlp.version()\n",
    "print(\"Apache Spark version\")\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_model(url, folder):\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    import urllib.request\n",
    "    import zipfile\n",
    "    zip_file = folder + \".zip\"\n",
    "    if not Path(zip_file).is_file():\n",
    "        print(\"Downloading \" + url)\n",
    "        urllib.request.urlretrieve(url, zip_file)\n",
    "    if not os.path.exists(folder):\n",
    "        print(\"Unziping \")\n",
    "        zip_ref = zipfile.ZipFile(zip_file, 'r')\n",
    "        zip_ref.extractall(\"./\")\n",
    "        zip_ref.close()\n",
    "\n",
    "\n",
    "def get_service_token_ids(source_bert_folder):\n",
    "    start_id = 0\n",
    "    end_id = 0\n",
    "    with open(os.path.join(source_bert_folder, \"vocab.txt\")) as f:\n",
    "        for line, row in enumerate(f):\n",
    "            row = row.strip()\n",
    "            if row == '[CLS]':\n",
    "                start_id = line\n",
    "            if row == '[SEP]':\n",
    "                end_id = line\n",
    "    return (start_id, end_id)\n",
    "\n",
    "\n",
    "def create_model(source_bert_folder, export_dir, max_sentence_length = 256, batch_size = 32):\n",
    "    tf.reset_default_graph()\n",
    "    is_cased = 'uncased' not in source_bert_folder.lower()\n",
    "    print(\"source_bert_folder: {}\".format(source_bert_folder))\n",
    "    print(\"is_cased: {}\".format(is_cased))\n",
    "    print(\"lowercase: {}\".format(not is_cased))\n",
    "    resolver = BertEmbeddingsResolver(source_bert_folder, max_sentence_length, lowercase = not is_cased)\n",
    "    saver = NerModelSaver(resolver, None)\n",
    "    saver.save_models(export_dir)\n",
    "    resolver.session.close()\n",
    "    shutil.copyfile(os.path.join(source_bert_folder, 'vocab.txt'),\n",
    "                    os.path.join(export_dir, 'vocab.txt'))\n",
    "\n",
    "    dim = resolver.config.hidden_size\n",
    "    layers = resolver.config.num_hidden_layers\n",
    "    print(\"Number of hidden units: {}\".format(dim))\n",
    "    print(\"Number of layers: {}\".format(layers))\n",
    "    \n",
    "    model = BertEmbeddings.loadFromPython(export_dir, spark) \\\n",
    "        .setInputCols([\"sentence\", \"token\"]) \\\n",
    "        .setOutputCol(\"embeddings\") \\\n",
    "        .setMaxSentenceLength(max_sentence_length) \\\n",
    "        .setBatchSize(batch_size) \\\n",
    "        .setDimension(dim) \\\n",
    "        .setCaseSensitive(is_cased)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def download_and_convert(url, name, max_sentence_length = 256, batch_size = 32, dst_folder = 'models'):\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    download_model(url, name)\n",
    "    model = create_model(name, name + 'export_dir', max_sentence_length, batch_size)\n",
    "    # Remove but it's possible to use this model\n",
    "    shutil.rmtree(name + 'export_dir')\n",
    "    shutil.rmtree(name)\n",
    "    final_model_name = name + '_M-{}'.format(max_sentence_length) + '_B-{}'.format(batch_size)\n",
    "    model.write().overwrite().save(os.path.join(dst_folder, final_model_name))\n",
    "    print(\"BERT model has been saved: {}\".format(dst_folder+'/'+final_model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find models and source code here https://github.com/google-research/bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unziping \n",
      "source_bert_folder: uncased_L-12_H-768_A-12\n",
      "is_cased: False\n",
      "lowercase: True\n",
      "INFO:tensorflow:Restoring parameters from uncased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n",
      "BERT model has been saved: models/uncased_L-12_H-768_A-12_M-256_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_60d730981579"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Base uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip'\n",
    "name = 'uncased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 256, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip\n",
      "Unziping \n",
      "source_bert_folder: uncased_L-24_H-1024_A-16\n",
      "is_cased: False\n",
      "lowercase: True\n",
      "INFO:tensorflow:Restoring parameters from uncased_L-24_H-1024_A-16/bert_model.ckpt\n",
      "Number of hidden units: 1024\n",
      "Number of layers: 24\n",
      "BERT model has been saved: models/uncased_L-24_H-1024_A-16_M-256_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_9041758dc1d0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Large uncased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-24_H-1024_A-16.zip'\n",
    "name = 'uncased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 256, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unziping \n",
      "source_bert_folder: cased_L-12_H-768_A-12\n",
      "is_cased: True\n",
      "lowercase: False\n",
      "INFO:tensorflow:Restoring parameters from cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n",
      "BERT model has been saved: models/cased_L-12_H-768_A-12_M-256_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_300bc72bdca3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Base cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip'\n",
    "name = 'cased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 256, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bert_folder: cased_L-24_H-1024_A-16\n",
      "is_cased: True\n",
      "lowercase: False\n",
      "INFO:tensorflow:Restoring parameters from cased_L-24_H-1024_A-16/bert_model.ckpt\n",
      "Number of hidden units: 1024\n",
      "Number of layers: 24\n",
      "BERT model has been saved: models/cased_L-24_H-1024_A-16_M-256_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_46b223b42b3f"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Large cased\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_10_18/cased_L-24_H-1024_A-16.zip'\n",
    "name = 'cased_L-24_H-1024_A-16'\n",
    "download_and_convert(url, name, max_sentence_length = 256, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
      "Unziping \n",
      "source_bert_folder: multi_cased_L-12_H-768_A-12\n",
      "is_cased: True\n",
      "lowercase: False\n",
      "INFO:tensorflow:Restoring parameters from multi_cased_L-12_H-768_A-12/bert_model.ckpt\n",
      "Number of hidden units: 768\n",
      "Number of layers: 12\n",
      "BERT model has been saved: models/multi_cased_L-12_H-768_A-12_M-256_B-32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERT_EMBEDDINGS_699908deafdb"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Multilingual Cased (New, recommended)\n",
    "url = 'https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip'\n",
    "name = 'multi_cased_L-12_H-768_A-12'\n",
    "download_and_convert(url, name, max_sentence_length = 256, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All generated models are inside \"models/\" directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
