package com.johnsnowlabs.nlp.annotators.sbd.deep

import com.johnsnowlabs.nlp.AnnotatorType.{CHUNK, DOCUMENT, TOKEN}
import com.johnsnowlabs.nlp.annotator.{SentenceDetector, Tokenizer}
import com.johnsnowlabs.nlp.annotators.common.SentenceSplit
import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, DocumentAssembler}
import org.apache.spark.ml.param.BooleanParam
import org.apache.spark.ml.util.Identifiable
import org.apache.spark.sql.SparkSession

class DeepSentenceDetector(override val uid: String) extends AnnotatorModel[DeepSentenceDetector]{

  def this() = this(Identifiable.randomUID("SENTENCE ML"))

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  override val requiredAnnotatorTypes: Array[AnnotatorType] = Array(DOCUMENT, TOKEN, CHUNK)
  override val annotatorType: AnnotatorType = DOCUMENT

  val includeRules = new BooleanParam(this, "includeRules",
    "Includes rule-based sentence detector as first filter")

  def setIncludeRules(value: Boolean): this.type = set(includeRules, value)
  setDefault(includeRules, false)

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {

    if ($(includeRules)) {

      val document = getDocument(annotations)

      val pragmaticSentenceDetector = new SentenceDetector().annotate(document)

      if (pragmaticSentenceDetector.length == 1 && pragmaticSentenceDetector.head.metadata == document.head.metadata){
        deepSentenceDetector(annotations)
      }
      else {

//        val segmentedSentences = pragmaticSentenceDetector.map(sentences =>
//
//        )
//
        val pruebas = pragmaticSentenceDetector
        pruebas
        //val tests = pragmaticSentenceDetector.map(sentence => deepSentenceDetector(Seq(sentence)))
        //Seq(Annotation(annotatorType, 0 , 0, "under construction", Map()))

      }
    } else {
      deepSentenceDetector(annotations)
    }

  }

  def getDocument(annotations: Seq[Annotation]): Seq[Annotation] = {
    annotations.filter(annotation => annotation.annotatorType == DOCUMENT)
  }

  def deepSentenceDetector(annotations: Seq[Annotation]): Seq[Annotation] = {
    val nerEntities = getNerEntities(annotations)
    val sentence = retrieveSentence(annotations)
    segmentSentence(nerEntities, sentence)
  }

  def getNerEntities(annotations: Seq[Annotation]): Seq[Annotation] = {
    annotations.filter(annotation => annotation.annotatorType == CHUNK)
  }

  def retrieveSentence(annotations: Seq[Annotation]): String = {
    val sentences = SentenceSplit.unpack(annotations)
    val sentence = sentences.map(sentence => sentence.content)
    sentence.mkString(" ")
  }

  def segmentSentence(nerEntities: Seq[Annotation], sentence: String): Seq[Annotation] = {
    var sentenceNumber = 0
    nerEntities.zipWithIndex.map{case (nerEntity, index) =>
      sentenceNumber += 1
      if (index != nerEntities.length-1){
        val beginIndex = nerEntity.begin
        val endIndex = nerEntities(index+1).begin-1
        val segmentedSentence = sentence.substring(beginIndex, endIndex)
        Annotation(annotatorType, 0, segmentedSentence.length-1, segmentedSentence,
                   Map("sentence" -> sentenceNumber.toString))
      } else {
        val beginIndex = nerEntity.begin
        val segmentedSentence = sentence.substring(beginIndex)
        Annotation(annotatorType, 0, segmentedSentence.length-1, segmentedSentence,
          Map("sentence" -> sentenceNumber.toString))
      }
    }
  }

  def sentenceHasPunctuation(sentence: String): Boolean = {
    //https://www.grammarly.com/blog/end-sentence-punctuation/
    val endOfSentencePunctuation = List(".", "!", "?")
    var hasPunctuation = false

    endOfSentencePunctuation.foreach(punctuation =>
      if (sentence.contains(punctuation)){
        hasPunctuation = true
      }
    )
    hasPunctuation
  }

  def retrieveValidNerEntities(annotations: Seq[Annotation], pragmaticSentenceDetector: Seq[Annotation]): Seq[Annotation] = {

    val unpunctuatedSentences = pragmaticSentenceDetector.filterNot(annotatedSentence =>
      sentenceHasPunctuation(annotatedSentence.result))

    val validNerEntities = annotations.filter{annotation =>
      //TODO: Filter chunks first
      val beginSentence = unpunctuatedSentences.head.begin
      val endSentence = unpunctuatedSentences.head.end

      if (beginSentence >= annotation.begin && endSentence <= annotation.end){

      }

      sentenceHasPunctuation(annotation.result)
    }


    Seq(Annotation(DOCUMENT, 0, 0, "under construction", Map()))
  }

}
