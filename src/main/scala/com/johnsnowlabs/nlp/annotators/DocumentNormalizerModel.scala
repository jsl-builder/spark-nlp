package com.johnsnowlabs.nlp.annotators

import com.johnsnowlabs.nlp.AnnotatorType.DOCUMENT
import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, ParamsAndFeaturesReadable}
import org.apache.spark.ml.param.{BooleanParam, Param, StringArrayParam}
import org.apache.spark.ml.util.Identifiable


class DocumentNormalizerModel(override val uid: String) extends AnnotatorModel[DocumentNormalizerModel] {

  val EmptyStr = ""

  /** normalization regex patterns which match will be removed from document
    *
    * @group Parameters
    **/
  val cleanupPatterns = new StringArrayParam(this, "cleanupPatterns", "normalization regex patterns which match will be removed from document")
  /** whether to convert strings to lowercase
    *
    * @group param
    **/
  val lowercase = new BooleanParam(this, "lowercase", "whether to convert strings to lowercase")

  /** removalPolicy to remove patterns from text with a given policy
    *
    * @group param
    **/
  val removalPolicy: Param[String] = new Param(this, "removalPolicy", "removalPolicy to remove pattern from text")

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  /** Input annotator type : DOCUMENT
    *
    * @group anno
    **/
  override val inputAnnotatorTypes: Array[AnnotatorType] = Array[AnnotatorType](DOCUMENT)

  /** Input annotator type : DOCUMENT
    *
    * @group anno
    **/
  override val outputAnnotatorType: AnnotatorType = DOCUMENT

  def this() = this(Identifiable.randomUID("DOCUMENT_NORMALIZER"))

  def setCleanUpPatterns(value: Array[String]): this.type = set(cleanupPatterns, value)

  /** Basic regex rule to identify a candidate for tokenization. Defaults to \\S+ which means anything not a space
    *
    * @group getParam
    **/
  def getCleanupPatterns: Array[String] = $(cleanupPatterns)

  /** Lowercase tokens, default true
    *
    * @group getParam
    **/
  def getLowercase: Boolean = $(lowercase)

  /** Lowercase tokens, default true
    *
    * @group setParam
    **/
  def setLowercase(value: Boolean): this.type = set(lowercase, value)

  /** pattern to grab from text as token candidates. Defaults \\S+
    *
    * @group setParam
    **/
  def setRemovalPolicy(value: String): this.type = set(removalPolicy, value)

  /** pattern to grab from text as token candidates. Defaults \\S+
    *
    * @group getParam
    **/
  def getRemovalPolicy: String = $(removalPolicy)

  private def withAllFormatter(text: String, replacement: String = EmptyStr): String ={
    val normalizedDocument = {
      get(cleanupPatterns).map(_.foldLeft(text)((currentText, compositeText) => {
        currentText.replaceAll(compositeText, replacement)
      })).getOrElse(text)
    }
    normalizedDocument
  }

  private def withPrettyAllFormatter(text: String) = {
    withAllFormatter(text).split("\\s+").map(_.trim).mkString(" ")
  }

  private def withFirstFormatter(text: String, replacement: String = EmptyStr): String = {
    val normalizedDocument = {
      get(cleanupPatterns).map(_.foldLeft(text)((currentText, compositeText) => {
        currentText.replaceFirst(compositeText, replacement)
      })).getOrElse(text)
    }
    normalizedDocument
  }

  private def withPrettyFirstFormatter(text: String) = {
    withFirstFormatter(text).split("\\s+").map(_.trim).mkString(" ")
  }

  private def applyRegexPatterns(text: String, patterns: Array[String])(policy: String) = {
    require(!text.isEmpty && patterns.length > 0 && !patterns(0).isEmpty && !policy.isEmpty)

    policy match {
      case "all" => withAllFormatter(text)
      case "pretty_all" => withPrettyAllFormatter(text)
      case "first" => withFirstFormatter(text)
      case "pretty_first" => withPrettyFirstFormatter(text)
      case _ => throw new Exception("Unknown policy parameter in DocumentNormalizer annotation.")
    }
  }

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    annotations.
      map(annotation =>
        Annotation(
          applyRegexPatterns(annotation.result, getCleanupPatterns)(getRemovalPolicy),
          annotation.metadata))
  }
}


object DocumentNormalizerModel extends ParamsAndFeaturesReadable[NormalizerModel]