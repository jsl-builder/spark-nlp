package com.johnsnowlabs.nlp.annotators.tokenizer.wordpiece

import com.johnsnowlabs.nlp.{Annotation, AnnotatorModel, ParamsAndFeaturesReadable}
import com.johnsnowlabs.nlp.AnnotatorType.{DOCUMENT, WORDPIECE}
import com.johnsnowlabs.nlp.annotators.common._
import com.johnsnowlabs.nlp.serialization.MapFeature
import org.apache.spark.ml.param.BooleanParam
import org.apache.spark.ml.util.Identifiable


class WordpieceTokenizerModel(override val uid: String) extends AnnotatorModel[WordpieceTokenizerModel] {
  val vocabulary: MapFeature[String, Int] = new MapFeature(this, "vocabulary")
  val lowercase = new BooleanParam(this, name="lowercase", "Should be lowercased")

  setDefault(lowercase, true)

  def setVocabulary(value: Map[String, Int]): this.type = set(vocabulary, value)
  def setLowercase(value: Boolean): this.type = set(lowercase, value)

  def this() = this(Identifiable.randomUID("WORDPIECE_TOKENIZER"))

  /**
    * takes a document and annotations and produces new annotations of this annotator's annotation type
    *
    * @param annotations Annotations that correspond to inputAnnotationCols generated by previous annotators if any
    * @return any number of annotations processed for every input annotation. Not necessary one to one relationship
    */
  override def annotate(annotations: Seq[Annotation]): Seq[Annotation] = {
    val basicTokenizer = new BasicTokenizer($(lowercase))
    val encoder = new WordpieceEncoder(vocabulary.getOrDefault)

    val sentences = SentenceSplit.unpack(annotations)
    val tokenized = sentences.map {s =>
      val tokens = basicTokenizer.tokenize(s)
      val wordpieceTokens = tokens.flatMap(token => encoder.encode(token))
      WordpieceTokenizedSentence(wordpieceTokens)
    }

    WordpieceTokenized.pack(tokenized)
  }

  /** Annotator reference id. Used to identify elements in metadata or to refer to this annotator type */
  override val inputAnnotatorTypes: Array[AnnotatorType] = Array[AnnotatorType](DOCUMENT)


  override val outputAnnotatorType: AnnotatorType = WORDPIECE
}

object WordpieceTokenizerModel extends ParamsAndFeaturesReadable[WordpieceTokenizerModel]
